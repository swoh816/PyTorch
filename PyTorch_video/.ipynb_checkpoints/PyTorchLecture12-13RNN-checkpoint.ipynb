{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as tc\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series** of input -> **Series** of output\n",
    "\n",
    "memories previous data to predict next output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Applications: **Series** of data.\n",
    "\n",
    "1. Time series prediction: predict stock prices etc.\n",
    "2. Language modelling (text generation): understand the current sentence from the previous context.\n",
    "3. Text sentiment analysis: \n",
    "4. Named entity recognition\n",
    "5. Translation\n",
    "6. Speech recognition\n",
    "7. Music composition\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know\n",
    "1. the number of classes (RNN problem is multiclass classification (i.e., predict one out of five) --> cross entropy.\n",
    "2. input size\n",
    "3. hidden size\n",
    "4. batch size\n",
    "5. sequence length\n",
    "6. number of layer of rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one-hot vectors to encode letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = [1,0,0,0]\n",
    "e = [0,1,0,0]\n",
    "l = [0,0,1,0]\n",
    "o = [0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1  0  0  0\n",
      "[torch.FloatTensor of size 1x1x4]\n",
      "\n",
      "OUT:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.5847  0.5382\n",
      "[torch.FloatTensor of size 1x1x2]\n",
      " HIDDEN:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.5847  0.5382\n",
      "[torch.FloatTensor of size 1x1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cell = tc.nn.RNN(4, 2)\n",
    "inputs = Variable(tc.Tensor([[h]]))\n",
    "hidden = Variable(tc.randn(1,1,2))\n",
    "\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(\"INPUT: \", inputs)\n",
    "print(\"OUT: \", out, \"HIDDEN: \", hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feed sequence of letters,** not character by character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1  0  0  0\n",
      "  0  1  0  0\n",
      "  0  0  1  0\n",
      "  0  0  1  0\n",
      "  0  0  0  1\n",
      "[torch.FloatTensor of size 1x5x4]\n",
      "\n",
      "OUT:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.8503 -0.2171\n",
      "  0.6434 -0.8183\n",
      "  0.4419 -0.1800\n",
      "  0.5729 -0.3833\n",
      "  0.7308  0.0717\n",
      "[torch.FloatTensor of size 1x5x2]\n",
      " HIDDEN:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.7308  0.0717\n",
      "[torch.FloatTensor of size 1x1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cell = tc.nn.RNN(input_size=4, hidden_size=2, batch_first=True)\n",
    "# By setting `batch_first=True`, the first element of shape becomes the batch size\n",
    "\n",
    "inputs = Variable(tc.Tensor([[h, e, l, l, o]]))\n",
    "hidden = Variable(tc.randn(1,1,2))\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(\"INPUT: \", inputs) # input size: 1X5X4. 1: batch size, 5: sequence size (h,e,l,l,o), 4: input dimension\n",
    "print(\"OUT: \", out, \"HIDDEN: \", hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "  1  0  0  0\n",
      "  0  1  0  0\n",
      "  0  0  1  0\n",
      "  0  0  1  0\n",
      "  0  0  0  1\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0  1  0  0\n",
      "  0  0  0  1\n",
      "  0  0  1  0\n",
      "  0  0  1  0\n",
      "  0  0  1  0\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0  0  1  0\n",
      "  0  0  1  0\n",
      "  0  1  0  0\n",
      "  0  1  0  0\n",
      "  0  0  1  0\n",
      "[torch.FloatTensor of size 3x5x4]\n",
      "\n",
      "OUT:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.4768 -0.8414\n",
      "  0.0143  0.1479\n",
      "  0.0582 -0.4436\n",
      "  0.1133 -0.4532\n",
      "  0.5292  0.0269\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.1859 -0.0919\n",
      "  0.4841 -0.0191\n",
      "  0.1183 -0.3717\n",
      "  0.1129 -0.4418\n",
      "  0.1184 -0.4446\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.1332 -0.5055\n",
      "  0.1258 -0.4432\n",
      " -0.0546  0.0938\n",
      " -0.1183  0.0773\n",
      "  0.0513 -0.4662\n",
      "[torch.FloatTensor of size 3x5x2]\n",
      " HIDDEN:  Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.5292  0.0269\n",
      "  0.1184 -0.4446\n",
      "  0.0513 -0.4662\n",
      "[torch.FloatTensor of size 1x3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc.manual_seed(1)\n",
    "cell = tc.nn.RNN(input_size=4, hidden_size=2, batch_first=True)\n",
    "# batch_first: If ``True``, then the input and output tensors are provided as (batch, seq, feature)\n",
    "\n",
    "# Three batches: hello, eolll, lleel\n",
    "inputs = Variable(tc.Tensor([[h,e,l,l,o],\n",
    "                            [e,o,l,l,l],\n",
    "                            [l,l,e,e,l]]))\n",
    "# input_size: torch.Size([3,5,4]): Batch size, sequence length, input dimension (one-hot size)\n",
    "\n",
    "hidden = Variable(tc.randn(1,3,2)) # num_layers*num_direction, num_batches, hidden_size\n",
    "# hidden = Variable(tc.randn(1,1,2)) works as well. WHY???????????????????????????????????????????????\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(\"INPUT: \", inputs) # input size: 3X5X4. 3: batch size, 5: sequence size (h,e,l,l,o), 4: input dimension\n",
    "print(\"OUT: \", out, \"HIDDEN: \", hidden) # input size: 3X5X4. 3: batch size, 5: sequence size (h,e,l,l,o), 4: hidden dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train our model to say \"hi hello\".\n",
    "\n",
    "The RNN model predicts which letter follows which letter.\n",
    "\n",
    "And we need to use **multi-label classification** because we determine which letter out of five (h,i,e,l,o) will follow the given letter.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = [1,0,0,0,0]\n",
    "i = [0,1,0,0,0]\n",
    "e = [0,0,1,0,0]\n",
    "l = [0,0,0,1,0]\n",
    "o = [0,0,0,0,1]\n",
    "letters = [h,i,e,l,o]\n",
    "\n",
    "letter_to_idx = {letter: idx for letter, idx in enumerate(letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "x_data = [0,1,0,2,3,3]\n",
    "one_hot_lookup = [[1,0,0,0,0],\n",
    "                 [0,1,0,0,0],\n",
    "                 [0,0,1,0,0],\n",
    "                 [0,0,0,1,0],\n",
    "                 [0,0,0,0,1],]\n",
    "\n",
    "y_data = [1,0,2,3,3,4]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "\n",
    "inputs = Variable(tc.Tensor(x_one_hot))\n",
    "labels = Variable(tc.LongTensor(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input_dim = 5: one-hot size ( == number of classes in this example)\n",
    "# sequence_length = 1\n",
    "# num_layers = 1: one-layer rnn\n",
    "# batch_size = 1: one sentence\n",
    "# hidden_dim = 5: output directly to a one-hot vector\n",
    "class Model(tc.nn.Module):\n",
    "    def __init__(self, input_dim, sequence_length, num_layers, batch_size, hidden_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.rnn = tc.nn.RNN(input_size=input_dim, hidden_size=self.hidden_dim, batch_first=True)\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        inputs = inputs.view(self.batch_size, self.sequence_length, self.input_dim)\n",
    "        out, hidden = self.rnn(inputs)\n",
    "        out = out.view(-1, self.input_dim)\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def initialize_hidden(self):\n",
    "        return Variable(tc.zeros(self.num_layers, self.batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
    "x_data = [0,1,0,2,3,3]\n",
    "one_hot_lookup = [[1,0,0,0,0],\n",
    "                 [0,1,0,0,0],\n",
    "                 [0,0,1,0,0],\n",
    "                 [0,0,0,1,0],\n",
    "                 [0,0,0,0,1],]\n",
    "\n",
    "y_data = [1,0,2,3,3,4]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "\n",
    "inputs = Variable(tc.Tensor(x_one_hot))\n",
    "labels = Variable(tc.LongTensor(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(5, 1, 1, 1, 5)\n",
    "criterion = tc.nn.CrossEntropyLoss()\n",
    "optimizer = tc.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.manual_seed(1)\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    hidden = model.initialize_hidden()\n",
    "    total_loss = 0\n",
    "    for inp, lab in zip(inputs, labels):\n",
    "        out, hidden = model(inp, hidden)\n",
    "        val, idx = out.max(1)\n",
    "        total_loss += criterion(out, lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 9.5889\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(5, 1, 1, 1, 5)\n",
    "criterion = tc.nn.CrossEntropyLoss()\n",
    "optimizer = tc.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: size '[1 x 1 x 5]' is invalid for input with 30 elements at /opt/conda/conda-bld/pytorch_1512387374934/work/torch/lib/TH/THStorage.c:41",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-ab014a91ee9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-188-7ece75533f74>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: size '[1 x 1 x 5]' is invalid for input with 30 elements at /opt/conda/conda-bld/pytorch_1512387374934/work/torch/lib/TH/THStorage.c:41"
     ]
    }
   ],
   "source": [
    "# tc.manual_seed(1)\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    hidden = model.initialize_hidden()\n",
    "    out, hidden = model(inputs, hidden)\n",
    "    loss = criterion(out, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.7382\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 0\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 4\n",
       "[torch.LongTensor of size 6]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
