{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as tc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Supervised learning\n",
    "\n",
    "\n",
    "## 1.1 Linear model\n",
    "\n",
    "### 1.1.1 Define regression model (forward pass) and loss function.\n",
    "Machine starts with **a random weight**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 1.0 # Random guess\n",
    "\n",
    "def forward(x): # Our model for the forward pass (prediction given the input)\n",
    "    return x*w\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimizing the loss is learning:**<br>\n",
    "<center>$argmin_w loss(w)$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Compute loss for `w`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w= 0.0\n",
      "\t 1.0 2.0 0.0 4.0\n",
      "\t 2.0 4.0 0.0 16.0\n",
      "\t 3.0 6.0 0.0 36.0\n",
      "MSE= 18.6666666667\n",
      "w= 0.1\n",
      "\t 1.0 2.0 0.1 3.61\n",
      "\t 2.0 4.0 0.2 14.44\n",
      "\t 3.0 6.0 0.3 32.49\n",
      "MSE= 16.8466666667\n",
      "w= 0.2\n",
      "\t 1.0 2.0 0.2 3.24\n",
      "\t 2.0 4.0 0.4 12.96\n",
      "\t 3.0 6.0 0.6 29.16\n",
      "MSE= 15.12\n",
      "w= 0.3\n",
      "\t 1.0 2.0 0.3 2.89\n",
      "\t 2.0 4.0 0.6 11.56\n",
      "\t 3.0 6.0 0.9 26.01\n",
      "MSE= 13.4866666667\n",
      "w= 0.4\n",
      "\t 1.0 2.0 0.4 2.56\n",
      "\t 2.0 4.0 0.8 10.24\n",
      "\t 3.0 6.0 1.2 23.04\n",
      "MSE= 11.9466666667\n",
      "w= 0.5\n",
      "\t 1.0 2.0 0.5 2.25\n",
      "\t 2.0 4.0 1.0 9.0\n",
      "\t 3.0 6.0 1.5 20.25\n",
      "MSE= 10.5\n",
      "w= 0.6\n",
      "\t 1.0 2.0 0.6 1.96\n",
      "\t 2.0 4.0 1.2 7.84\n",
      "\t 3.0 6.0 1.8 17.64\n",
      "MSE= 9.14666666667\n",
      "w= 0.7\n",
      "\t 1.0 2.0 0.7 1.69\n",
      "\t 2.0 4.0 1.4 6.76\n",
      "\t 3.0 6.0 2.1 15.21\n",
      "MSE= 7.88666666667\n",
      "w= 0.8\n",
      "\t 1.0 2.0 0.8 1.44\n",
      "\t 2.0 4.0 1.6 5.76\n",
      "\t 3.0 6.0 2.4 12.96\n",
      "MSE= 6.72\n",
      "w= 0.9\n",
      "\t 1.0 2.0 0.9 1.21\n",
      "\t 2.0 4.0 1.8 4.84\n",
      "\t 3.0 6.0 2.7 10.89\n",
      "MSE= 5.64666666667\n",
      "w= 1.0\n",
      "\t 1.0 2.0 1.0 1.0\n",
      "\t 2.0 4.0 2.0 4.0\n",
      "\t 3.0 6.0 3.0 9.0\n",
      "MSE= 4.66666666667\n",
      "w= 1.1\n",
      "\t 1.0 2.0 1.1 0.81\n",
      "\t 2.0 4.0 2.2 3.24\n",
      "\t 3.0 6.0 3.3 7.29\n",
      "MSE= 3.78\n",
      "w= 1.2\n",
      "\t 1.0 2.0 1.2 0.64\n",
      "\t 2.0 4.0 2.4 2.56\n",
      "\t 3.0 6.0 3.6 5.76\n",
      "MSE= 2.98666666667\n",
      "w= 1.3\n",
      "\t 1.0 2.0 1.3 0.49\n",
      "\t 2.0 4.0 2.6 1.96\n",
      "\t 3.0 6.0 3.9 4.41\n",
      "MSE= 2.28666666667\n",
      "w= 1.4\n",
      "\t 1.0 2.0 1.4 0.36\n",
      "\t 2.0 4.0 2.8 1.44\n",
      "\t 3.0 6.0 4.2 3.24\n",
      "MSE= 1.68\n",
      "w= 1.5\n",
      "\t 1.0 2.0 1.5 0.25\n",
      "\t 2.0 4.0 3.0 1.0\n",
      "\t 3.0 6.0 4.5 2.25\n",
      "MSE= 1.16666666667\n",
      "w= 1.6\n",
      "\t 1.0 2.0 1.6 0.16\n",
      "\t 2.0 4.0 3.2 0.64\n",
      "\t 3.0 6.0 4.8 1.44\n",
      "MSE= 0.746666666667\n",
      "w= 1.7\n",
      "\t 1.0 2.0 1.7 0.09\n",
      "\t 2.0 4.0 3.4 0.36\n",
      "\t 3.0 6.0 5.1 0.81\n",
      "MSE= 0.42\n",
      "w= 1.8\n",
      "\t 1.0 2.0 1.8 0.04\n",
      "\t 2.0 4.0 3.6 0.16\n",
      "\t 3.0 6.0 5.4 0.36\n",
      "MSE= 0.186666666667\n",
      "w= 1.9\n",
      "\t 1.0 2.0 1.9 0.01\n",
      "\t 2.0 4.0 3.8 0.04\n",
      "\t 3.0 6.0 5.7 0.09\n",
      "MSE= 0.0466666666667\n",
      "w= 2.0\n",
      "\t 1.0 2.0 2.0 0.0\n",
      "\t 2.0 4.0 4.0 0.0\n",
      "\t 3.0 6.0 6.0 0.0\n",
      "MSE= 0.0\n",
      "w= 2.1\n",
      "\t 1.0 2.0 2.1 0.01\n",
      "\t 2.0 4.0 4.2 0.04\n",
      "\t 3.0 6.0 6.3 0.09\n",
      "MSE= 0.0466666666667\n",
      "w= 2.2\n",
      "\t 1.0 2.0 2.2 0.04\n",
      "\t 2.0 4.0 4.4 0.16\n",
      "\t 3.0 6.0 6.6 0.36\n",
      "MSE= 0.186666666667\n",
      "w= 2.3\n",
      "\t 1.0 2.0 2.3 0.09\n",
      "\t 2.0 4.0 4.6 0.36\n",
      "\t 3.0 6.0 6.9 0.81\n",
      "MSE= 0.42\n",
      "w= 2.4\n",
      "\t 1.0 2.0 2.4 0.16\n",
      "\t 2.0 4.0 4.8 0.64\n",
      "\t 3.0 6.0 7.2 1.44\n",
      "MSE= 0.746666666667\n",
      "w= 2.5\n",
      "\t 1.0 2.0 2.5 0.25\n",
      "\t 2.0 4.0 5.0 1.0\n",
      "\t 3.0 6.0 7.5 2.25\n",
      "MSE= 1.16666666667\n",
      "w= 2.6\n",
      "\t 1.0 2.0 2.6 0.36\n",
      "\t 2.0 4.0 5.2 1.44\n",
      "\t 3.0 6.0 7.8 3.24\n",
      "MSE= 1.68\n",
      "w= 2.7\n",
      "\t 1.0 2.0 2.7 0.49\n",
      "\t 2.0 4.0 5.4 1.96\n",
      "\t 3.0 6.0 8.1 4.41\n",
      "MSE= 2.28666666667\n",
      "w= 2.8\n",
      "\t 1.0 2.0 2.8 0.64\n",
      "\t 2.0 4.0 5.6 2.56\n",
      "\t 3.0 6.0 8.4 5.76\n",
      "MSE= 2.98666666667\n",
      "w= 2.9\n",
      "\t 1.0 2.0 2.9 0.81\n",
      "\t 2.0 4.0 5.8 3.24\n",
      "\t 3.0 6.0 8.7 7.29\n",
      "MSE= 3.78\n",
      "w= 3.0\n",
      "\t 1.0 2.0 3.0 1.0\n",
      "\t 2.0 4.0 6.0 4.0\n",
      "\t 3.0 6.0 9.0 9.0\n",
      "MSE= 4.66666666667\n",
      "w= 3.1\n",
      "\t 1.0 2.0 3.1 1.21\n",
      "\t 2.0 4.0 6.2 4.84\n",
      "\t 3.0 6.0 9.3 10.89\n",
      "MSE= 5.64666666667\n",
      "w= 3.2\n",
      "\t 1.0 2.0 3.2 1.44\n",
      "\t 2.0 4.0 6.4 5.76\n",
      "\t 3.0 6.0 9.6 12.96\n",
      "MSE= 6.72\n",
      "w= 3.3\n",
      "\t 1.0 2.0 3.3 1.69\n",
      "\t 2.0 4.0 6.6 6.76\n",
      "\t 3.0 6.0 9.9 15.21\n",
      "MSE= 7.88666666667\n",
      "w= 3.4\n",
      "\t 1.0 2.0 3.4 1.96\n",
      "\t 2.0 4.0 6.8 7.84\n",
      "\t 3.0 6.0 10.2 17.64\n",
      "MSE= 9.14666666667\n",
      "w= 3.5\n",
      "\t 1.0 2.0 3.5 2.25\n",
      "\t 2.0 4.0 7.0 9.0\n",
      "\t 3.0 6.0 10.5 20.25\n",
      "MSE= 10.5\n",
      "w= 3.6\n",
      "\t 1.0 2.0 3.6 2.56\n",
      "\t 2.0 4.0 7.2 10.24\n",
      "\t 3.0 6.0 10.8 23.04\n",
      "MSE= 11.9466666667\n",
      "w= 3.7\n",
      "\t 1.0 2.0 3.7 2.89\n",
      "\t 2.0 4.0 7.4 11.56\n",
      "\t 3.0 6.0 11.1 26.01\n",
      "MSE= 13.4866666667\n",
      "w= 3.8\n",
      "\t 1.0 2.0 3.8 3.24\n",
      "\t 2.0 4.0 7.6 12.96\n",
      "\t 3.0 6.0 11.4 29.16\n",
      "MSE= 15.12\n",
      "w= 3.9\n",
      "\t 1.0 2.0 3.9 3.61\n",
      "\t 2.0 4.0 7.8 14.44\n",
      "\t 3.0 6.0 11.7 32.49\n",
      "MSE= 16.8466666667\n",
      "w= 4.0\n",
      "\t 1.0 2.0 4.0 4.0\n",
      "\t 2.0 4.0 8.0 16.0\n",
      "\t 3.0 6.0 12.0 36.0\n",
      "MSE= 18.6666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe28b252358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "\n",
    "w = 1.0\n",
    "\n",
    "w_list = []\n",
    "mse_list = []\n",
    "for w in np.arange(0.0, 4.1, 0.1):\n",
    "    print(\"w=\", w)\n",
    "    l_sum = 0\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        y_pred_val = forward(x_val)\n",
    "        l = loss(x_val, y_val)\n",
    "        l_sum += l\n",
    "        print(\"\\t\", x_val, y_val, y_pred_val, l)\n",
    "        \n",
    "    print(\"MSE=\", l_sum/3) # The mean of loss (we have three features in our example)\n",
    "    w_list.append(w)\n",
    "    mse_list.append(l_sum/3)\n",
    "    \n",
    "# print(mse_list)\n",
    "plt.plot(w_list, mse_list)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Gradient descent\n",
    "\n",
    "Gradient descent is a way to **update weight.** You calculate **the gradient of the model** you use to predict. If gradient is:\n",
    "1. negative, you increase the weight.\n",
    "2. positive, you decrease the weight.\n",
    "\n",
    "<center>$w = w - \\alpha \\frac{\\delta loss}{\\delta w}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(x, y):\n",
    "    return 2*x*(x*w - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 4.0\n",
      "\tgrad:  1.0 2.0 -2.0\n",
      "\tgrad:  2.0 4.0 -7.84\n",
      "\tgrad:  3.0 6.0 -16.2288\n",
      "progress: 0 w= 1.260688 loss= 4.919240100095999\n",
      "\tgrad:  1.0 2.0 -1.478624\n",
      "\tgrad:  2.0 4.0 -5.796206079999999\n",
      "\tgrad:  3.0 6.0 -11.998146585599997\n",
      "progress: 1 w= 1.453417766656 loss= 2.688769240265834\n",
      "\tgrad:  1.0 2.0 -1.093164466688\n",
      "\tgrad:  2.0 4.0 -4.285204709416961\n",
      "\tgrad:  3.0 6.0 -8.87037374849311\n",
      "progress: 2 w= 1.5959051959019805 loss= 1.4696334962911515\n",
      "\tgrad:  1.0 2.0 -0.8081896081960389\n",
      "\tgrad:  2.0 4.0 -3.1681032641284723\n",
      "\tgrad:  3.0 6.0 -6.557973756745939\n",
      "progress: 3 w= 1.701247862192685 loss= 0.8032755585999681\n",
      "\tgrad:  1.0 2.0 -0.59750427561463\n",
      "\tgrad:  2.0 4.0 -2.3422167604093502\n",
      "\tgrad:  3.0 6.0 -4.848388694047353\n",
      "progress: 4 w= 1.7791289594933983 loss= 0.43905614881022015\n",
      "\tgrad:  1.0 2.0 -0.44174208101320334\n",
      "\tgrad:  2.0 4.0 -1.7316289575717576\n",
      "\tgrad:  3.0 6.0 -3.584471942173538\n",
      "progress: 5 w= 1.836707389300983 loss= 0.2399802903801062\n",
      "\tgrad:  1.0 2.0 -0.3265852213980338\n",
      "\tgrad:  2.0 4.0 -1.2802140678802925\n",
      "\tgrad:  3.0 6.0 -2.650043120512205\n",
      "progress: 6 w= 1.8792758133988885 loss= 0.1311689630744999\n",
      "\tgrad:  1.0 2.0 -0.241448373202223\n",
      "\tgrad:  2.0 4.0 -0.946477622952715\n",
      "\tgrad:  3.0 6.0 -1.9592086795121197\n",
      "progress: 7 w= 1.910747160155559 loss= 0.07169462478267678\n",
      "\tgrad:  1.0 2.0 -0.17850567968888198\n",
      "\tgrad:  2.0 4.0 -0.6997422643804168\n",
      "\tgrad:  3.0 6.0 -1.4484664872674653\n",
      "progress: 8 w= 1.9340143044689266 loss= 0.03918700813247573\n",
      "\tgrad:  1.0 2.0 -0.13197139106214673\n",
      "\tgrad:  2.0 4.0 -0.5173278529636143\n",
      "\tgrad:  3.0 6.0 -1.0708686556346834\n",
      "progress: 9 w= 1.9512159834655312 loss= 0.021418922423117836\n",
      "\tgrad:  1.0 2.0 -0.09756803306893769\n",
      "\tgrad:  2.0 4.0 -0.38246668963023644\n",
      "\tgrad:  3.0 6.0 -0.7917060475345892\n",
      "progress: 10 w= 1.9639333911678687 loss= 0.01170720245384975\n",
      "\tgrad:  1.0 2.0 -0.07213321766426262\n",
      "\tgrad:  2.0 4.0 -0.2827622132439096\n",
      "\tgrad:  3.0 6.0 -0.5853177814148953\n",
      "progress: 11 w= 1.9733355232910992 loss= 0.006398948863435593\n",
      "\tgrad:  1.0 2.0 -0.05332895341780164\n",
      "\tgrad:  2.0 4.0 -0.2090494973977819\n",
      "\tgrad:  3.0 6.0 -0.4327324596134101\n",
      "progress: 12 w= 1.9802866323953892 loss= 0.003497551760830656\n",
      "\tgrad:  1.0 2.0 -0.039426735209221686\n",
      "\tgrad:  2.0 4.0 -0.15455280202014876\n",
      "\tgrad:  3.0 6.0 -0.3199243001817109\n",
      "progress: 13 w= 1.9854256707695 loss= 0.001911699652671057\n",
      "\tgrad:  1.0 2.0 -0.02914865846100012\n",
      "\tgrad:  2.0 4.0 -0.11426274116712065\n",
      "\tgrad:  3.0 6.0 -0.2365238742159388\n",
      "progress: 14 w= 1.9892250235079405 loss= 0.0010449010656399273\n",
      "\tgrad:  1.0 2.0 -0.021549952984118992\n",
      "\tgrad:  2.0 4.0 -0.08447581569774698\n",
      "\tgrad:  3.0 6.0 -0.17486493849433593\n",
      "progress: 15 w= 1.9920339305797026 loss= 0.0005711243580809696\n",
      "\tgrad:  1.0 2.0 -0.015932138840594856\n",
      "\tgrad:  2.0 4.0 -0.062453984255132156\n",
      "\tgrad:  3.0 6.0 -0.12927974740812687\n",
      "progress: 16 w= 1.994110589284741 loss= 0.0003121664271570621\n",
      "\tgrad:  1.0 2.0 -0.011778821430517894\n",
      "\tgrad:  2.0 4.0 -0.046172980007630926\n",
      "\tgrad:  3.0 6.0 -0.09557806861579543\n",
      "progress: 17 w= 1.9956458879852805 loss= 0.0001706246229305199\n",
      "\tgrad:  1.0 2.0 -0.008708224029438938\n",
      "\tgrad:  2.0 4.0 -0.03413623819540135\n",
      "\tgrad:  3.0 6.0 -0.07066201306448505\n",
      "progress: 18 w= 1.9967809527381737 loss= 9.326038746484765e-05\n",
      "\tgrad:  1.0 2.0 -0.006438094523652627\n",
      "\tgrad:  2.0 4.0 -0.02523733053271826\n",
      "\tgrad:  3.0 6.0 -0.052241274202728505\n",
      "progress: 19 w= 1.9976201197307648 loss= 5.097447086306101e-05\n",
      "\tgrad:  1.0 2.0 -0.004759760538470381\n",
      "\tgrad:  2.0 4.0 -0.01865826131080439\n",
      "\tgrad:  3.0 6.0 -0.03862260091336722\n",
      "progress: 20 w= 1.998240525958391 loss= 2.7861740127856012e-05\n",
      "\tgrad:  1.0 2.0 -0.0035189480832178432\n",
      "\tgrad:  2.0 4.0 -0.01379427648621423\n",
      "\tgrad:  3.0 6.0 -0.028554152326460525\n",
      "progress: 21 w= 1.99869919972735 loss= 1.5228732143933469e-05\n",
      "\tgrad:  1.0 2.0 -0.002601600545300009\n",
      "\tgrad:  2.0 4.0 -0.01019827413757568\n",
      "\tgrad:  3.0 6.0 -0.021110427464781978\n",
      "progress: 22 w= 1.9990383027488265 loss= 8.323754426231206e-06\n",
      "\tgrad:  1.0 2.0 -0.001923394502346909\n",
      "\tgrad:  2.0 4.0 -0.007539706449199102\n",
      "\tgrad:  3.0 6.0 -0.01560719234984198\n",
      "progress: 23 w= 1.9992890056818404 loss= 4.549616284094891e-06\n",
      "\tgrad:  1.0 2.0 -0.0014219886363191492\n",
      "\tgrad:  2.0 4.0 -0.005574195454370212\n",
      "\tgrad:  3.0 6.0 -0.011538584590544687\n",
      "progress: 24 w= 1.999474353368653 loss= 2.486739429417538e-06\n",
      "\tgrad:  1.0 2.0 -0.0010512932626940419\n",
      "\tgrad:  2.0 4.0 -0.004121069589761106\n",
      "\tgrad:  3.0 6.0 -0.008530614050808794\n",
      "progress: 25 w= 1.9996113831376856 loss= 1.3592075910762856e-06\n",
      "\tgrad:  1.0 2.0 -0.0007772337246287897\n",
      "\tgrad:  2.0 4.0 -0.0030467562005451754\n",
      "\tgrad:  3.0 6.0 -0.006306785335127074\n",
      "progress: 26 w= 1.9997126908902887 loss= 7.429187207079447e-07\n",
      "\tgrad:  1.0 2.0 -0.0005746182194226179\n",
      "\tgrad:  2.0 4.0 -0.002252503420136165\n",
      "\tgrad:  3.0 6.0 -0.00466268207967957\n",
      "progress: 27 w= 1.9997875889274812 loss= 4.060661735575354e-07\n",
      "\tgrad:  1.0 2.0 -0.0004248221450375844\n",
      "\tgrad:  2.0 4.0 -0.0016653028085471533\n",
      "\tgrad:  3.0 6.0 -0.0034471768136938863\n",
      "progress: 28 w= 1.9998429619451539 loss= 2.2194855602869353e-07\n",
      "\tgrad:  1.0 2.0 -0.00031407610969225175\n",
      "\tgrad:  2.0 4.0 -0.0012311783499932005\n",
      "\tgrad:  3.0 6.0 -0.0025485391844828342\n",
      "progress: 29 w= 1.9998838998815958 loss= 1.213131374411496e-07\n",
      "\tgrad:  1.0 2.0 -0.00023220023680847746\n",
      "\tgrad:  2.0 4.0 -0.0009102249282886277\n",
      "\tgrad:  3.0 6.0 -0.0018841656015560204\n",
      "progress: 30 w= 1.9999141657892625 loss= 6.630760559646474e-08\n",
      "\tgrad:  1.0 2.0 -0.00017166842147497974\n",
      "\tgrad:  2.0 4.0 -0.0006729402121816719\n",
      "\tgrad:  3.0 6.0 -0.0013929862392156878\n",
      "progress: 31 w= 1.9999365417379913 loss= 3.624255915449335e-08\n",
      "\tgrad:  1.0 2.0 -0.0001269165240174175\n",
      "\tgrad:  2.0 4.0 -0.0004975127741477792\n",
      "\tgrad:  3.0 6.0 -0.0010298514424817995\n",
      "progress: 32 w= 1.9999530845453979 loss= 1.9809538924707548e-08\n",
      "\tgrad:  1.0 2.0 -9.383090920422887e-05\n",
      "\tgrad:  2.0 4.0 -0.00036781716408107457\n",
      "\tgrad:  3.0 6.0 -0.0007613815296476645\n",
      "progress: 33 w= 1.9999653148414271 loss= 1.0827542027017377e-08\n",
      "\tgrad:  1.0 2.0 -6.937031714571162e-05\n",
      "\tgrad:  2.0 4.0 -0.0002719316432120422\n",
      "\tgrad:  3.0 6.0 -0.0005628985014531906\n",
      "progress: 34 w= 1.999974356846045 loss= 5.9181421028034105e-09\n",
      "\tgrad:  1.0 2.0 -5.1286307909848006e-05\n",
      "\tgrad:  2.0 4.0 -0.00020104232700646207\n",
      "\tgrad:  3.0 6.0 -0.0004161576169003922\n",
      "progress: 35 w= 1.9999810417085633 loss= 3.2347513278475087e-09\n",
      "\tgrad:  1.0 2.0 -3.7916582873442906e-05\n",
      "\tgrad:  2.0 4.0 -0.0001486330048638962\n",
      "\tgrad:  3.0 6.0 -0.0003076703200690645\n",
      "progress: 36 w= 1.9999859839076413 loss= 1.7680576050779005e-09\n",
      "\tgrad:  1.0 2.0 -2.8032184717474706e-05\n",
      "\tgrad:  2.0 4.0 -0.0001098861640933535\n",
      "\tgrad:  3.0 6.0 -0.00022746435967313516\n",
      "progress: 37 w= 1.9999896377347262 loss= 9.6638887447731e-10\n",
      "\tgrad:  1.0 2.0 -2.0724530547688857e-05\n",
      "\tgrad:  2.0 4.0 -8.124015974608767e-05\n",
      "\tgrad:  3.0 6.0 -0.00016816713067413502\n",
      "progress: 38 w= 1.999992339052936 loss= 5.282109892545845e-10\n",
      "\tgrad:  1.0 2.0 -1.5321894128117464e-05\n",
      "\tgrad:  2.0 4.0 -6.006182498197177e-05\n",
      "\tgrad:  3.0 6.0 -0.00012432797771566584\n",
      "progress: 39 w= 1.9999943361699042 loss= 2.887107421958329e-10\n",
      "\tgrad:  1.0 2.0 -1.1327660191629008e-05\n",
      "\tgrad:  2.0 4.0 -4.4404427951505454e-05\n",
      "\tgrad:  3.0 6.0 -9.191716585732479e-05\n",
      "progress: 40 w= 1.9999958126624442 loss= 1.5780416225633037e-10\n",
      "\tgrad:  1.0 2.0 -8.37467511161094e-06\n",
      "\tgrad:  2.0 4.0 -3.282872643772805e-05\n",
      "\tgrad:  3.0 6.0 -6.795546372551087e-05\n",
      "progress: 41 w= 1.999996904251097 loss= 8.625295142578772e-11\n",
      "\tgrad:  1.0 2.0 -6.191497806007362e-06\n",
      "\tgrad:  2.0 4.0 -2.4270671399762023e-05\n",
      "\tgrad:  3.0 6.0 -5.0240289795056015e-05\n",
      "progress: 42 w= 1.999997711275687 loss= 4.71443308235547e-11\n",
      "\tgrad:  1.0 2.0 -4.5774486259198e-06\n",
      "\tgrad:  2.0 4.0 -1.794359861406747e-05\n",
      "\tgrad:  3.0 6.0 -3.714324913239864e-05\n",
      "progress: 43 w= 1.9999983079186507 loss= 2.5768253628059826e-11\n",
      "\tgrad:  1.0 2.0 -3.3841626985164908e-06\n",
      "\tgrad:  2.0 4.0 -1.326591777761621e-05\n",
      "\tgrad:  3.0 6.0 -2.7460449796734565e-05\n",
      "progress: 44 w= 1.9999987490239537 loss= 1.4084469615916932e-11\n",
      "\tgrad:  1.0 2.0 -2.5019520926150562e-06\n",
      "\tgrad:  2.0 4.0 -9.807652203264183e-06\n",
      "\tgrad:  3.0 6.0 -2.0301840059744336e-05\n",
      "progress: 45 w= 1.9999990751383971 loss= 7.698320862431846e-12\n",
      "\tgrad:  1.0 2.0 -1.8497232057157476e-06\n",
      "\tgrad:  2.0 4.0 -7.250914967116273e-06\n",
      "\tgrad:  3.0 6.0 -1.5009393983689279e-05\n",
      "progress: 46 w= 1.9999993162387186 loss= 4.20776540913866e-12\n",
      "\tgrad:  1.0 2.0 -1.3675225627451937e-06\n",
      "\tgrad:  2.0 4.0 -5.3606884460322135e-06\n",
      "\tgrad:  3.0 6.0 -1.109662508014253e-05\n",
      "progress: 47 w= 1.9999994944870796 loss= 2.299889814334344e-12\n",
      "\tgrad:  1.0 2.0 -1.0110258408246864e-06\n",
      "\tgrad:  2.0 4.0 -3.963221296032771e-06\n",
      "\tgrad:  3.0 6.0 -8.20386808086937e-06\n",
      "progress: 48 w= 1.9999996262682318 loss= 1.2570789110540446e-12\n",
      "\tgrad:  1.0 2.0 -7.474635363990956e-07\n",
      "\tgrad:  2.0 4.0 -2.930057062755509e-06\n",
      "\tgrad:  3.0 6.0 -6.065218119744031e-06\n",
      "progress: 49 w= 1.999999723695619 loss= 6.870969979249939e-13\n",
      "\tgrad:  1.0 2.0 -5.526087618612507e-07\n",
      "\tgrad:  2.0 4.0 -2.166226346744793e-06\n",
      "\tgrad:  3.0 6.0 -4.484088535150477e-06\n",
      "progress: 50 w= 1.9999997957248556 loss= 3.7555501141274804e-13\n",
      "\tgrad:  1.0 2.0 -4.08550288710785e-07\n",
      "\tgrad:  2.0 4.0 -1.6015171322436572e-06\n",
      "\tgrad:  3.0 6.0 -3.3151404608133817e-06\n",
      "progress: 51 w= 1.9999998489769344 loss= 2.052716967104274e-13\n",
      "\tgrad:  1.0 2.0 -3.020461312175371e-07\n",
      "\tgrad:  2.0 4.0 -1.1840208351543424e-06\n",
      "\tgrad:  3.0 6.0 -2.4509231284497446e-06\n",
      "progress: 52 w= 1.9999998883468353 loss= 1.1219786256679713e-13\n",
      "\tgrad:  1.0 2.0 -2.2330632942768602e-07\n",
      "\tgrad:  2.0 4.0 -8.753608113920563e-07\n",
      "\tgrad:  3.0 6.0 -1.811996877876254e-06\n",
      "progress: 53 w= 1.9999999174534755 loss= 6.132535848018759e-14\n",
      "\tgrad:  1.0 2.0 -1.6509304900935717e-07\n",
      "\tgrad:  2.0 4.0 -6.471647520100987e-07\n",
      "\tgrad:  3.0 6.0 -1.3396310407642886e-06\n",
      "progress: 54 w= 1.999999938972364 loss= 3.351935118167793e-14\n",
      "\tgrad:  1.0 2.0 -1.220552721115098e-07\n",
      "\tgrad:  2.0 4.0 -4.784566662863199e-07\n",
      "\tgrad:  3.0 6.0 -9.904052991061008e-07\n",
      "progress: 55 w= 1.9999999548815364 loss= 1.8321081844499955e-14\n",
      "\tgrad:  1.0 2.0 -9.023692726373156e-08\n",
      "\tgrad:  2.0 4.0 -3.5372875473171916e-07\n",
      "\tgrad:  3.0 6.0 -7.322185204827747e-07\n",
      "progress: 56 w= 1.9999999666433785 loss= 1.0013977760018664e-14\n",
      "\tgrad:  1.0 2.0 -6.671324292994996e-08\n",
      "\tgrad:  2.0 4.0 -2.615159129248923e-07\n",
      "\tgrad:  3.0 6.0 -5.413379398078177e-07\n",
      "progress: 57 w= 1.9999999753390494 loss= 5.473462367088053e-15\n",
      "\tgrad:  1.0 2.0 -4.932190122985958e-08\n",
      "\tgrad:  2.0 4.0 -1.9334185274999527e-07\n",
      "\tgrad:  3.0 6.0 -4.002176350326181e-07\n",
      "progress: 58 w= 1.9999999817678633 loss= 2.991697274308627e-15\n",
      "\tgrad:  1.0 2.0 -3.6464273378555845e-08\n",
      "\tgrad:  2.0 4.0 -1.429399514307761e-07\n",
      "\tgrad:  3.0 6.0 -2.9588569994132286e-07\n",
      "progress: 59 w= 1.9999999865207625 loss= 1.6352086111474931e-15\n",
      "\tgrad:  1.0 2.0 -2.6958475007887728e-08\n",
      "\tgrad:  2.0 4.0 -1.0567722164012139e-07\n",
      "\tgrad:  3.0 6.0 -2.1875184863517916e-07\n",
      "progress: 60 w= 1.999999990034638 loss= 8.937759877335403e-16\n",
      "\tgrad:  1.0 2.0 -1.993072418216002e-08\n",
      "\tgrad:  2.0 4.0 -7.812843882959442e-08\n",
      "\tgrad:  3.0 6.0 -1.617258700292723e-07\n",
      "progress: 61 w= 1.9999999926324883 loss= 4.885220495987371e-16\n",
      "\tgrad:  1.0 2.0 -1.473502342363986e-08\n",
      "\tgrad:  2.0 4.0 -5.7761292637792394e-08\n",
      "\tgrad:  3.0 6.0 -1.195658771990793e-07\n",
      "progress: 62 w= 1.99999999455311 loss= 2.670175009618106e-16\n",
      "\tgrad:  1.0 2.0 -1.0893780100218464e-08\n",
      "\tgrad:  2.0 4.0 -4.270361841918202e-08\n",
      "\tgrad:  3.0 6.0 -8.839649012770678e-08\n",
      "progress: 63 w= 1.9999999959730488 loss= 1.4594702493172377e-16\n",
      "\tgrad:  1.0 2.0 -8.05390243385773e-09\n",
      "\tgrad:  2.0 4.0 -3.1571296688071016e-08\n",
      "\tgrad:  3.0 6.0 -6.53525820126788e-08\n",
      "progress: 64 w= 1.9999999970228268 loss= 7.977204100704301e-17\n",
      "\tgrad:  1.0 2.0 -5.9543463493128e-09\n",
      "\tgrad:  2.0 4.0 -2.334103754719763e-08\n",
      "\tgrad:  3.0 6.0 -4.8315948575350376e-08\n",
      "progress: 65 w= 1.9999999977989402 loss= 4.360197735196887e-17\n",
      "\tgrad:  1.0 2.0 -4.402119557767037e-09\n",
      "\tgrad:  2.0 4.0 -1.725630838222969e-08\n",
      "\tgrad:  3.0 6.0 -3.5720557178819945e-08\n",
      "progress: 66 w= 1.9999999983727301 loss= 2.3832065197304227e-17\n",
      "\tgrad:  1.0 2.0 -3.254539748809293e-09\n",
      "\tgrad:  2.0 4.0 -1.2757796596929438e-08\n",
      "\tgrad:  3.0 6.0 -2.6408640607655798e-08\n",
      "progress: 67 w= 1.9999999987969397 loss= 1.3026183953845832e-17\n",
      "\tgrad:  1.0 2.0 -2.406120636067044e-09\n",
      "\tgrad:  2.0 4.0 -9.431992964437086e-09\n",
      "\tgrad:  3.0 6.0 -1.9524227568012975e-08\n",
      "progress: 68 w= 1.999999999110563 loss= 7.11988308874388e-18\n",
      "\tgrad:  1.0 2.0 -1.7788739370416806e-09\n",
      "\tgrad:  2.0 4.0 -6.97318647269185e-09\n",
      "\tgrad:  3.0 6.0 -1.4434496264925656e-08\n",
      "progress: 69 w= 1.9999999993424284 loss= 3.89160224698574e-18\n",
      "\tgrad:  1.0 2.0 -1.3151431055291596e-09\n",
      "\tgrad:  2.0 4.0 -5.155360582875801e-09\n",
      "\tgrad:  3.0 6.0 -1.067159693945996e-08\n",
      "progress: 70 w= 1.9999999995138495 loss= 2.1270797208746147e-18\n",
      "\tgrad:  1.0 2.0 -9.72300906454393e-10\n",
      "\tgrad:  2.0 4.0 -3.811418736177075e-09\n",
      "\tgrad:  3.0 6.0 -7.88963561149103e-09\n",
      "progress: 71 w= 1.9999999996405833 loss= 1.1626238773828175e-18\n",
      "\tgrad:  1.0 2.0 -7.18833437218791e-10\n",
      "\tgrad:  2.0 4.0 -2.8178277489132597e-09\n",
      "\tgrad:  3.0 6.0 -5.832902161273523e-09\n",
      "progress: 72 w= 1.999999999734279 loss= 6.354692062078993e-19\n",
      "\tgrad:  1.0 2.0 -5.314420015167798e-10\n",
      "\tgrad:  2.0 4.0 -2.0832526814729135e-09\n",
      "\tgrad:  3.0 6.0 -4.31233715403323e-09\n",
      "progress: 73 w= 1.9999999998035491 loss= 3.4733644793346653e-19\n",
      "\tgrad:  1.0 2.0 -3.92901711165905e-10\n",
      "\tgrad:  2.0 4.0 -1.5401742103904326e-09\n",
      "\tgrad:  3.0 6.0 -3.188159070077745e-09\n",
      "progress: 74 w= 1.9999999998547615 loss= 1.8984796531526204e-19\n",
      "\tgrad:  1.0 2.0 -2.9047697580608656e-10\n",
      "\tgrad:  2.0 4.0 -1.1386696030513122e-09\n",
      "\tgrad:  3.0 6.0 -2.3570478902001923e-09\n",
      "progress: 75 w= 1.9999999998926234 loss= 1.0376765851119951e-19\n",
      "\tgrad:  1.0 2.0 -2.1475310418850313e-10\n",
      "\tgrad:  2.0 4.0 -8.418314934033333e-10\n",
      "\tgrad:  3.0 6.0 -1.7425900722400911e-09\n",
      "progress: 76 w= 1.9999999999206153 loss= 5.671751114309842e-20\n",
      "\tgrad:  1.0 2.0 -1.5876944203796484e-10\n",
      "\tgrad:  2.0 4.0 -6.223768167501476e-10\n",
      "\tgrad:  3.0 6.0 -1.2883241140571045e-09\n",
      "progress: 77 w= 1.9999999999413098 loss= 3.100089617511693e-20\n",
      "\tgrad:  1.0 2.0 -1.17380327679939e-10\n",
      "\tgrad:  2.0 4.0 -4.601314884666863e-10\n",
      "\tgrad:  3.0 6.0 -9.524754318590567e-10\n",
      "progress: 78 w= 1.9999999999566096 loss= 1.6944600977692705e-20\n",
      "\tgrad:  1.0 2.0 -8.678080476443029e-11\n",
      "\tgrad:  2.0 4.0 -3.4018121652934497e-10\n",
      "\tgrad:  3.0 6.0 -7.041780492045291e-10\n",
      "progress: 79 w= 1.9999999999679208 loss= 9.2616919156479e-21\n",
      "\tgrad:  1.0 2.0 -6.415845632545825e-11\n",
      "\tgrad:  2.0 4.0 -2.5150193039280566e-10\n",
      "\tgrad:  3.0 6.0 -5.206075570640678e-10\n",
      "progress: 80 w= 1.9999999999762834 loss= 5.062350511130293e-21\n",
      "\tgrad:  1.0 2.0 -4.743316850408519e-11\n",
      "\tgrad:  2.0 4.0 -1.8593837580738182e-10\n",
      "\tgrad:  3.0 6.0 -3.8489211817704927e-10\n",
      "progress: 81 w= 1.999999999982466 loss= 2.7669155644059242e-21\n",
      "\tgrad:  1.0 2.0 -3.5067948545020045e-11\n",
      "\tgrad:  2.0 4.0 -1.3746692673066718e-10\n",
      "\tgrad:  3.0 6.0 -2.845563784603655e-10\n",
      "progress: 82 w= 1.9999999999870368 loss= 1.5124150106147723e-21\n",
      "\tgrad:  1.0 2.0 -2.5926372160256506e-11\n",
      "\tgrad:  2.0 4.0 -1.0163070385260653e-10\n",
      "\tgrad:  3.0 6.0 -2.1037571684701106e-10\n",
      "progress: 83 w= 1.999999999990416 loss= 8.26683933105326e-22\n",
      "\tgrad:  1.0 2.0 -1.9167778475548403e-11\n",
      "\tgrad:  2.0 4.0 -7.51381179497912e-11\n",
      "\tgrad:  3.0 6.0 -1.5553425214420713e-10\n",
      "progress: 84 w= 1.9999999999929146 loss= 4.518126871054872e-22\n",
      "\tgrad:  1.0 2.0 -1.4170886686315498e-11\n",
      "\tgrad:  2.0 4.0 -5.555023108172463e-11\n",
      "\tgrad:  3.0 6.0 -1.1499068364173581e-10\n",
      "progress: 85 w= 1.9999999999947617 loss= 2.469467919185614e-22\n",
      "\tgrad:  1.0 2.0 -1.0476508549572827e-11\n",
      "\tgrad:  2.0 4.0 -4.106759377009439e-11\n",
      "\tgrad:  3.0 6.0 -8.500933290633839e-11\n",
      "progress: 86 w= 1.9999999999961273 loss= 1.349840097651456e-22\n",
      "\tgrad:  1.0 2.0 -7.745359908994942e-12\n",
      "\tgrad:  2.0 4.0 -3.036149109902908e-11\n",
      "\tgrad:  3.0 6.0 -6.285105769165966e-11\n",
      "progress: 87 w= 1.999999999997137 loss= 7.376551550022107e-23\n",
      "\tgrad:  1.0 2.0 -5.726086271806707e-12\n",
      "\tgrad:  2.0 4.0 -2.2446045022661565e-11\n",
      "\tgrad:  3.0 6.0 -4.646416584819235e-11\n",
      "progress: 88 w= 1.9999999999978835 loss= 4.031726170507742e-23\n",
      "\tgrad:  1.0 2.0 -4.233058348290797e-12\n",
      "\tgrad:  2.0 4.0 -1.659294923683774e-11\n",
      "\tgrad:  3.0 6.0 -3.4351188560322043e-11\n",
      "progress: 89 w= 1.9999999999984353 loss= 2.2033851437431755e-23\n",
      "\tgrad:  1.0 2.0 -3.1294966618133913e-12\n",
      "\tgrad:  2.0 4.0 -1.226752033289813e-11\n",
      "\tgrad:  3.0 6.0 -2.539835008974478e-11\n",
      "progress: 90 w= 1.9999999999988431 loss= 1.2047849775995315e-23\n",
      "\tgrad:  1.0 2.0 -2.3137047833188262e-12\n",
      "\tgrad:  2.0 4.0 -9.070078021977679e-12\n",
      "\tgrad:  3.0 6.0 -1.8779644506139448e-11\n",
      "progress: 91 w= 1.9999999999991447 loss= 6.5840863393251405e-24\n",
      "\tgrad:  1.0 2.0 -1.7106316363424412e-12\n",
      "\tgrad:  2.0 4.0 -6.7057470687359455e-12\n",
      "\tgrad:  3.0 6.0 -1.3882228699912957e-11\n",
      "progress: 92 w= 1.9999999999993676 loss= 3.5991747246272455e-24\n",
      "\tgrad:  1.0 2.0 -1.2647660696529783e-12\n",
      "\tgrad:  2.0 4.0 -4.957811938766099e-12\n",
      "\tgrad:  3.0 6.0 -1.0263789818054647e-11\n",
      "progress: 93 w= 1.9999999999995324 loss= 1.969312363793734e-24\n",
      "\tgrad:  1.0 2.0 -9.352518759442319e-13\n",
      "\tgrad:  2.0 4.0 -3.666400516522117e-12\n",
      "\tgrad:  3.0 6.0 -7.58859641791787e-12\n",
      "progress: 94 w= 1.9999999999996543 loss= 1.0761829795642296e-24\n",
      "\tgrad:  1.0 2.0 -6.914468997365475e-13\n",
      "\tgrad:  2.0 4.0 -2.7107205369247822e-12\n",
      "\tgrad:  3.0 6.0 -5.611511255665391e-12\n",
      "progress: 95 w= 1.9999999999997444 loss= 5.875191475205477e-25\n",
      "\tgrad:  1.0 2.0 -5.111466805374221e-13\n",
      "\tgrad:  2.0 4.0 -2.0037305148434825e-12\n",
      "\tgrad:  3.0 6.0 -4.1460168631601846e-12\n",
      "progress: 96 w= 1.999999999999811 loss= 3.2110109830478153e-25\n",
      "\tgrad:  1.0 2.0 -3.779199175824033e-13\n",
      "\tgrad:  2.0 4.0 -1.4814816040598089e-12\n",
      "\tgrad:  3.0 6.0 -3.064215547965432e-12\n",
      "progress: 97 w= 1.9999999999998603 loss= 1.757455879087579e-25\n",
      "\tgrad:  1.0 2.0 -2.793321129956894e-13\n",
      "\tgrad:  2.0 4.0 -1.0942358130705543e-12\n",
      "\tgrad:  3.0 6.0 -2.2648549702353193e-12\n",
      "progress: 98 w= 1.9999999999998967 loss= 9.608404711682446e-26\n",
      "\tgrad:  1.0 2.0 -2.0650148258027912e-13\n",
      "\tgrad:  2.0 4.0 -8.100187187665142e-13\n",
      "\tgrad:  3.0 6.0 -1.6786572132332367e-12\n",
      "progress: 99 w= 1.9999999999999236 loss= 5.250973729513143e-26\n",
      "predict (after training) 4 hours 7.9999999999996945\n"
     ]
    }
   ],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = 1.0 # Random guess\n",
    "\n",
    "def forward(x): # Our model for the forward pass (prediction given the input)\n",
    "    return x*w\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y)**2\n",
    "\n",
    "# Before training\n",
    "print(\"predict (before training)\", 4, forward(4))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100): # epoch: how many times are we going to update weight\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        grad = gradient(x_val, y_val)\n",
    "        w = w - 0.01*grad # learning rate = 0.01\n",
    "        print(\"\\tgrad: \", x_val, y_val, grad)\n",
    "        l = loss(x_val, y_val)\n",
    "        \n",
    "    print(\"progress:\", epoch, \"w=\", w, \"loss=\", l)\n",
    "    \n",
    "# After training\n",
    "print(\"predict (after training)\", \"4 hours\", forward(4))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Backpropagation\n",
    "\n",
    "Use `Variable` to compute gradient.\n",
    "All the operation on `Variable` will construct a computational graph. You should claim it using `requires_grad` local argument.\n",
    "\n",
    "<center>`x = Variable(tc.ones(3,3), requires_grad=True)`</center>\n",
    "\n",
    "With computational graph, you can perform `backward()` on it to compute gradient. You can use the gradient with respect to a `Variable` using `Variable.grad.data`.\n",
    "\n",
    "You can return the value of `Variable` using `Variable.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2.0000\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch as tc\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def forward_pass(x_val):\n",
    "    return w*x_val\n",
    "\n",
    "def loss(x_val, y_val):\n",
    "    return (forward_pass(x_val) - y_val)**2\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = Variable(tc.Tensor([1.0]), requires_grad = True)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        # 1. Run through forward pass\n",
    "        l = loss(x_val, y_val)\n",
    "        # 2. Calculate backprop\n",
    "        l.backward()\n",
    "        # 3. Update weight\n",
    "        w.data = w.data - 0.01*w.grad.data\n",
    "        # IMPORTANT: Initialize our gradient by manually making the gradient zero after updating weight\n",
    "        w.grad.data.zero_()\n",
    "print(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
